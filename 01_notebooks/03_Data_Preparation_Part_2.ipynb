{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5f1c02-a977-4d1d-88d7-a3373daca394",
   "metadata": {},
   "source": [
    "# **Pride and Joy**\n",
    "### *An investigation of mental health correlates in LGBQ+ people*\n",
    "| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |\n",
    "|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|Emily K. Sanders| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |Capstone Project|\n",
    "|DSB-318| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |June 13, 2024|\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffb837-3f23-4198-8cf6-3afdc0e4a3a0",
   "metadata": {},
   "source": [
    "## Prior Notebooks Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da37ca2-6bca-4f17-a827-b7dd0755a9e7",
   "metadata": {},
   "source": [
    "In the previous notebook, I ingested the data, changed the column names, conducted a first round of feature selection, and resolved all missing values.\n",
    "\n",
    "In this notebook, I will demonstrate how I used `python` to finish preparing the data for modeling through feature engineering.  Specifically, I will recode columns as necessary and create new features that are composite scores of existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f47f8d-57cd-4ba8-82d8-291ccf08b202",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e4baf-bd96-4e2d-8c04-206c7cc8d87d",
   "metadata": {},
   "source": [
    "- [Data Preparation](#data-preparation-continued)\n",
    "  - [Imports](#imports)\n",
    "  - [Feature Engineering](#feature-engineering)\n",
    "    - [Recoding Variables](#recoding-variables)\n",
    "    - [Creating Composite Variables](#creating-composite-variables)\n",
    "- [Notebook Summary](#notebook-summary)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea8683-7899-4337-8cee-07d09b4c674b",
   "metadata": {},
   "source": [
    "## Data Preparation, Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c98f5-3a6d-4571-b591-fc13b02a774a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922c5699-26f7-4cf7-ab2e-c4768286fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from warnings import simplefilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169af9e7-b0ba-45e2-aa4b-b2db69578311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings preferences\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "# Thanks to daydaybroskii and KingOtto at Stack Overflow for that one\n",
    "# https://stackoverflow.com/questions/68292862/performancewarning-dataframe-is-highly-fragmented-this-is-usually-the-result-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f3d103-e0a2-42da-ad63-93dcf234bbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 225)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data - mine\n",
    "meyer = pd.read_csv('../02_data/df_after_data_preparation_part_1.csv') \n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9d559-ede7-4773-98d0-727fa3dce0a3",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd61c530-bd78-4725-a756-134f7ec1ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to hold groups of columns and some instructions - more on this later\n",
    "feat_eng_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec4ece-8ec8-4936-ac92-c54e8d952c44",
   "metadata": {},
   "source": [
    "#### Recoding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d7abf-8ed1-4f34-9638-a4f289799385",
   "metadata": {},
   "source": [
    "say some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8268e629-9d75-4e04-b5b8-29d36fc10e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'w1q89_ei' - 7s like 97s\n",
    "# This is the question about how often people smoke cigarettes, and the 7s are people who \n",
    "# said on the previous question that they do not smoke. Therefore, I imputed \"not at all\" here.\n",
    "cond = meyer['w1q89_ei']==7.0\n",
    "meyer.loc[cond, 'w1q89_ei']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b692cb2d-068d-4c7d-b809-9bb75bb42b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 225)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of the 123 questions are about outness, but they're coded unintuitively. \"Are you out to...\"\n",
    "# 1 = All, 2 = Most, 3 = Some, 4 = None, 5 = don't know/does not apply/[missing value]\n",
    "# I recoded it like this:\n",
    "# 4 -> 0 = I can confidently say I am out to \"None\" of these people. (LOWEST OUTNESS)\n",
    "# 5 -> 1 = I'm being wishy-washy about how out I am to these people.\n",
    "# 3 -> 2 = Some\n",
    "# 2 -> 3 = Most\n",
    "# 1 -> 4 = All (HIGHEST OUTNESS)\n",
    "\n",
    "# Create new columns\n",
    "meyer[['w1q123a_ei_r', 'w1q123b_ei_r', 'w1q123c_ei_r', 'w1q123d_ei_r']] = meyer[[\n",
    "  'w1q123a_ei', 'w1q123b_ei', 'w1q123c_ei', 'w1q123d_ei']]\n",
    "\n",
    "# Create a recoding dictionary\n",
    "recode_123s = {4: 0, 5: 1, 3: 2, 2: 3, 1: 4}\n",
    "\n",
    "# Create lists\n",
    "old_cols = ['w1q123a_ei', 'w1q123b_ei', 'w1q123c_ei', 'w1q123d_ei']\n",
    "new_cols = ['w1q123a_ei_r', 'w1q123b_ei_r', 'w1q123c_ei_r', 'w1q123d_ei_r']\n",
    "\n",
    "# Recode\n",
    "for old, new in list(zip(old_cols, new_cols)):\n",
    "  meyer[new] = meyer[old].map(recode_123s)\n",
    "\n",
    "# Drop the old versions\n",
    "meyer.drop(columns = old_cols, inplace = True)\n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fee3fd8-18ee-43ec-bab3-82eed40d2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 124, about visibility, needs to be reverse coded so that higher numbers = more visibly queer\n",
    "\n",
    "# Adjust the values in a new column\n",
    "meyer[['w1q124_ei_r']] = 5-meyer[['w1q124_ei']]\n",
    "\n",
    "# Drop the original\n",
    "meyer.drop(columns = ['w1q124_ei'], inplace = True)\n",
    "\n",
    "# Add an entry to the dictionary - more on this later\n",
    "feat_eng_dict['outness'] = ['mean', 'w1q123a_ei_r', 'w1q123b_ei_r', \n",
    "  'w1q123c_ei_r', 'w1q123d_ei_r', 'w1q124_ei_r']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99184d9-80a5-4804-96e0-588ca467dba4",
   "metadata": {},
   "source": [
    "Rather than typing out the syntax above over and over for each column, I wrote a function to generate most of the code I would need.  All I had to do was tinker with it to adjust the values correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae655b5a-afa7-4876-92e3-b998e0d7fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode(dictry, name, cols):\n",
    "  '''cols is a list of columns that need to be recoded.  \n",
    "  name is the name I want to give the composite column based on cols\n",
    "  dict is the STRING name of the dictionary (I need that for the func to modify it)\n",
    "    this function will spit out the appropriate syntax, but only for THIS df.'''\n",
    "  for i in cols[1:]:\n",
    "    print(f\"meyer[['{i}_r']] = meyer[['{i}']]\")\n",
    "  print('')\n",
    "  for i in cols[1:]:\n",
    "    # Note: These counts won't show in the Jupyter output, but they were helpful when I was working.\n",
    "    print(f\"meyer['{i}'].value_counts(dropna = False).sort_index()\")\n",
    "    print(f\"meyer['{i}_r'].value_counts(dropna = False).sort_index()\")\n",
    "  print('')\n",
    "  print(f\"meyer.drop(columns = {cols[1:]}).shape\")\n",
    "  print(f\"meyer.drop(columns = {cols[1:]}, inplace = True)\")\n",
    "  print('')\n",
    "  cols_r = cols[:1] + [''.join([x, '_r']) for x in cols[1:]]\n",
    "  print(f\"{dictry}['{name}'] = {cols_r}\")\n",
    "# I then ran this a bunch of times to generate the code seen below. \n",
    "# One example is provided, but the rest are omitted for space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6db566a-b1ec-49f4-9a6f-f59a3c6307fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meyer[['w1q19a_ei_r']] = meyer[['w1q19a_ei']]\n",
      "meyer[['w1q19b_ei_r']] = meyer[['w1q19b_ei']]\n",
      "meyer[['w1q19c_ei_r']] = meyer[['w1q19c_ei']]\n",
      "meyer[['w1q19d_ei_r']] = meyer[['w1q19d_ei']]\n",
      "\n",
      "meyer['w1q19a_ei'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19a_ei_r'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19b_ei'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19b_ei_r'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19c_ei'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19c_ei_r'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19d_ei'].value_counts(dropna = False).sort_index()\n",
      "meyer['w1q19d_ei_r'].value_counts(dropna = False).sort_index()\n",
      "\n",
      "meyer.drop(columns = ['w1q19a_ei', 'w1q19b_ei', 'w1q19c_ei', 'w1q19d_ei']).shape\n",
      "meyer.drop(columns = ['w1q19a_ei', 'w1q19b_ei', 'w1q19c_ei', 'w1q19d_ei'], inplace = True)\n",
      "\n",
      "feat_eng_dict['bad_neighbhd'] = ['sum', 'w1q19a_ei_r', 'w1q19b_ei_r', 'w1q19c_ei_r', 'w1q19d_ei_r']\n"
     ]
    }
   ],
   "source": [
    "recode('feat_eng_dict', 'bad_neighbhd', ['sum', 'w1q19a_ei', 'w1q19b_ei', 'w1q19c_ei', 'w1q19d_ei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb56f08-10e1-494e-b00a-882dfcd9ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 19 is about whether their neighborhood is a good place to live for people of different\n",
    "# identities.  I reverse coded it so that 1=bad neighborhood and 0=fine\n",
    "meyer[['w1q19a_ei_r']] = meyer[['w1q19a_ei']]-1\n",
    "meyer[['w1q19b_ei_r']] = meyer[['w1q19b_ei']]-1\n",
    "meyer[['w1q19c_ei_r']] = meyer[['w1q19c_ei']]-1\n",
    "meyer[['w1q19d_ei_r']] = meyer[['w1q19d_ei']]-1\n",
    "\n",
    "meyer['w1q19a_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19a_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19b_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19b_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19c_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19c_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19d_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q19d_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q19a_ei', 'w1q19b_ei', 'w1q19c_ei', 'w1q19d_ei']).shape  # See note above\n",
    "meyer.drop(columns = ['w1q19a_ei', 'w1q19b_ei', 'w1q19c_ei', 'w1q19d_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['bad_neighbhd'] = ['sum', 'w1q19a_ei_r', 'w1q19b_ei_r', 'w1q19c_ei_r', 'w1q19d_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086dac4f-83fc-4b2d-9e1c-d63a9ae6f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 75 and 76 ask if the participant has a disability, with 1=disabled, 2=non-disabled\n",
    "# I reverse coded these so that 1=disabled, 0=non-disabled\n",
    "meyer[['w1q75_ei_r']] = abs(meyer[['w1q75_ei']]-2)\n",
    "meyer[['w1q76_ei_r']] = abs(meyer[['w1q76_ei']]-2)\n",
    "\n",
    "meyer['w1q75_ei'].value_counts(dropna = False, sort = True, ascending = True)\n",
    "meyer['w1q75_ei_r'].value_counts(dropna = False, sort = True, ascending = True)\n",
    "meyer['w1q76_ei'].value_counts(dropna = False, sort = True, ascending = True)\n",
    "meyer['w1q76_ei_r'].value_counts(dropna = False, sort = True, ascending = True)\n",
    "\n",
    "meyer.drop(columns = ['w1q75_ei', 'w1q76_ei']).shape\n",
    "meyer.drop(columns = ['w1q75_ei', 'w1q76_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['disabled'] = ['binarize', 'w1q75_ei_r', 'w1q76_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca706077-eb77-4a91-9516-59f22b7044a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 'w1q101_ei', 'w1q105_ei', 'w1q109_ei', and 'w1q114_ei' are about suicidal ideation and\n",
    "# behavior, with 1=never, 2=once, and 3=more than once.  I adjusted the first 3 so that 0=never, 1=once, \n",
    "# and 2=more than once.  I did this for a lot of variables, and refer to it as \"0-basing\" throughout.\n",
    "meyer[['w1q101_ei_r']] = meyer[['w1q101_ei']]-1\n",
    "meyer[['w1q105_ei_r']] = meyer[['w1q105_ei']]-1\n",
    "meyer[['w1q109_ei_r']] = meyer[['w1q109_ei']]-1\n",
    "\n",
    "meyer['w1q101_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q101_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q105_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q105_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q109_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q109_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q101_ei', 'w1q105_ei', 'w1q109_ei']).shape\n",
    "meyer.drop(columns = ['w1q101_ei', 'w1q105_ei', 'w1q109_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['suicidality'] = ['sum', 'w1q101_ei_r', 'w1q105_ei_r', 'w1q109_ei_r', 'w1q114_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d4e250-ad59-4ee2-bf93-5761acc00ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 135 has sub-questions, all asking about different types of victimization the participant \n",
    "# may have experienced in their life.  I 0-based these so that 0=\"Never.\"\n",
    "meyer[['w1q135a_ei_r']] = meyer[['w1q135a_ei']]-1\n",
    "meyer[['w1q135b_ei_r']] = meyer[['w1q135b_ei']]-1\n",
    "meyer[['w1q135c_ei_r']] = meyer[['w1q135c_ei']]-1\n",
    "meyer[['w1q135d_ei_r']] = meyer[['w1q135d_ei']]-1\n",
    "meyer[['w1q135e_ei_r']] = meyer[['w1q135e_ei']]-1\n",
    "meyer[['w1q135f_ei_r']] = meyer[['w1q135f_ei']]-1\n",
    "\n",
    "meyer['w1q135a_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135a_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135b_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135b_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135c_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135c_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135d_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135d_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135e_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135e_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135f_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q135f_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q135a_ei', 'w1q135b_ei', 'w1q135c_ei', 'w1q135d_ei', 'w1q135e_ei', 'w1q135f_ei']).shape\n",
    "meyer.drop(columns = ['w1q135a_ei', 'w1q135b_ei', 'w1q135c_ei', 'w1q135d_ei', 'w1q135e_ei', 'w1q135f_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['abusive_treatment'] = ['sum', 'w1q135a_ei_r', 'w1q135b_ei_r', 'w1q135c_ei_r', 'w1q135d_ei_r', 'w1q135e_ei_r', 'w1q135f_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e53c3e-ca7d-441f-9ac3-819783fadcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 137 and 138 ask about workplace discrimination.  I 0-based these so that 0=\"Never.\"\n",
    "meyer[['w1q137_ei_r']] = meyer[['w1q137_ei']]-1\n",
    "meyer[['w1q138_ei_r']] = meyer[['w1q138_ei']]-1\n",
    "\n",
    "meyer['w1q137_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q137_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q138_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q138_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q137_ei', 'w1q138_ei']).shape\n",
    "meyer.drop(columns = ['w1q137_ei', 'w1q138_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['work_neg_outcomes'] = ['sum', 'w1q137_ei_r', 'w1q138_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8adb44a1-6a83-40a0-ac28-aa8e64772f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 142 has sub-questions, all asking about different types of stress the participant \n",
    "# may have experienced in the past year.  I recoded them so that 0 = \"No\" and 1 = \"Yes.\"\n",
    "# Note: I have broken these across different cells because they are part of different sub-scales of 142.\n",
    "meyer[['w1q142a_ei_r']] = abs(meyer[['w1q142a_ei']]-2)\n",
    "meyer[['w1q142h_ei_r']] = abs(meyer[['w1q142h_ei']]-2)\n",
    "meyer[['w1q142i_ei_r']] = abs(meyer[['w1q142i_ei']]-2)\n",
    "\n",
    "meyer['w1q142a_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142a_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142h_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142h_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142i_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142i_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q142a_ei', 'w1q142h_ei', 'w1q142i_ei']).shape\n",
    "meyer.drop(columns = ['w1q142a_ei', 'w1q142h_ei', 'w1q142i_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['stress_past_year_gen'] = ['sum', 'w1q142a_ei_r', 'w1q142h_ei_r', 'w1q142i_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f02550c3-3490-4e53-b8ce-7bd462c3cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meyer[['w1q142b_ei_r']] = abs(meyer[['w1q142b_ei']]-2)\n",
    "meyer[['w1q142c_ei_r']] = abs(meyer[['w1q142c_ei']]-2)\n",
    "meyer[['w1q142e_ei_r']] = abs(meyer[['w1q142e_ei']]-2)\n",
    "\n",
    "meyer['w1q142b_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142b_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142c_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142c_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142e_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142e_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q142b_ei', 'w1q142c_ei', 'w1q142e_ei']).shape\n",
    "meyer.drop(columns = ['w1q142b_ei', 'w1q142c_ei', 'w1q142e_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['stress_past_year_work'] = ['sum', 'w1q142b_ei_r', 'w1q142c_ei_r', 'w1q142e_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c74a8e-0745-491e-a132-edc45fdcc4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meyer[['w1q142d_ei_r']] = abs(meyer[['w1q142d_ei']]-2)\n",
    "meyer[['w1q142f_ei_r']] = abs(meyer[['w1q142f_ei']]-2)\n",
    "meyer[['w1q142g_ei_r']] = abs(meyer[['w1q142g_ei']]-2)\n",
    "\n",
    "meyer['w1q142d_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142d_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142f_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142f_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142g_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142g_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q142d_ei', 'w1q142f_ei', 'w1q142g_ei']).shape\n",
    "meyer.drop(columns = ['w1q142d_ei', 'w1q142f_ei', 'w1q142g_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['stress_past_year_interpersonal'] = ['sum', 'w1q142d_ei_r', 'w1q142f_ei_r', 'w1q142g_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "968c9632-e5ea-4949-97f7-d7996b155978",
   "metadata": {},
   "outputs": [],
   "source": [
    "meyer[['w1q142j_ei_r']] = abs(meyer[['w1q142j_ei']]-2)\n",
    "meyer[['w1q142k_ei_r']] = abs(meyer[['w1q142k_ei']]-2)\n",
    "\n",
    "meyer['w1q142j_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142j_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142k_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q142k_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q142j_ei', 'w1q142k_ei']).shape\n",
    "meyer.drop(columns = ['w1q142j_ei', 'w1q142k_ei'], inplace = True)\n",
    "\n",
    "feat_eng_dict['stress_past_year_crime'] = ['sum', 'w1q142j_ei_r', 'w1q142k_ei_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c07ac9-0db9-438f-a8bf-1a7cf942129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1q179_ei\n",
      "1.0     291\n",
      "2.0     133\n",
      "3.0      10\n",
      "4.0       6\n",
      "5.0      38\n",
      "6.0       2\n",
      "7.0      30\n",
      "8.0       1\n",
      "9.0     190\n",
      "10.0    153\n",
      "11.0    260\n",
      "12.0     94\n",
      "13.0    286\n",
      "Name: count, dtype: int64\n",
      "w1q180_ei\n",
      "1.0     689\n",
      "2.0     435\n",
      "3.0      29\n",
      "4.0       7\n",
      "5.0      51\n",
      "6.0       2\n",
      "7.0       3\n",
      "8.0       1\n",
      "9.0      23\n",
      "10.0     16\n",
      "11.0     25\n",
      "12.0     50\n",
      "13.0    163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question 179 asks which, if any, religion the participant practices, and question 180 asks which they \n",
    "# were raised in.  The original survey offered 13 options (see p. 261-262 of 37166-0007-Codebook-ICPSR.pdf), \n",
    "# but many categories had very few people in them.  Given how many features I had relative to observations,\n",
    "# I opted to consolidate these categories into 3 options: \n",
    "# 0 = Atheist, Agnostic, or \"Nothing in particular\" (roughly: not religious)\n",
    "# 1 = Protestant, Roman Catholic, Mormon, Orthodox (roughly: religous, Christian)\n",
    "# 5 = Jewish, Muslim, Buddhist, Hindu, Spiritual, \"Something else\" (roughly: religous, not Christian)\n",
    "# I kept 5, rather than recoding to 2, because it was the original code for Jewish, the most populous \n",
    "# original category in the new group.  All three columns would be One-Hot Encoded later anyway.\n",
    "\n",
    "# To see the original counts:\n",
    "print(meyer['w1q179_ei'].value_counts(dropna = False).sort_index())\n",
    "print(meyer['w1q180_ei'].value_counts(dropna = False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dfbbc16-9e8b-474b-9803-3fae066c4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the religion columns\n",
    "relig_recode = {1: 1, 2: 1, 3: 1, 4: 1, \n",
    "  5: 5, 6: 5, 7: 5, 8: 5, 11: 5, 12: 5, \n",
    "  9: 0, 10: 0, 13: 0} \n",
    "\n",
    "# Recode in new columns\n",
    "meyer['w1q179_ei_r'] = meyer['w1q179_ei'].map(relig_recode)\n",
    "meyer['w1q180_ei_r'] = meyer['w1q180_ei'].map(relig_recode)\n",
    "\n",
    "meyer['w1q179_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q179_ei_r'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q180_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q180_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q179_ei', 'w1q180_ei']).shape\n",
    "meyer.drop(columns = ['w1q179_ei', 'w1q180_ei'], inplace = True)\n",
    "\n",
    "# No dictionary entry - it doesn't make sense to combine these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03b62de-eca7-4735-b374-f2058f70b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 225)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape - make sure I have the same number of columns I started with\n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c064dd7-91c9-456c-8f55-9db2170bbfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1494, 229)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encode religion columns\n",
    "\n",
    "# Instantiate the transformers\n",
    "ohe = OneHotEncoder(drop = None, # I want to manually drop specific ones\n",
    "  handle_unknown = 'ignore', sparse_output = False) \n",
    "\n",
    "ctx = ColumnTransformer(transformers=[('one_hot', ohe, ['w1q179_ei_r', 'w1q180_ei_r'])],\n",
    "    remainder = 'passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "# Encode\n",
    "meyer_ohe = pd.DataFrame(data = ctx.fit_transform(meyer), \n",
    "  columns = ctx.get_feature_names_out())\n",
    "\n",
    "# Make sure the shape matches\n",
    "print(meyer_ohe.shape)\n",
    "meyer_ohe.shape == (meyer.shape[0], meyer.shape[1]+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c6178cf-77d9-4348-ad96-a497711e4a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 227)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-religious ones so they're the baseline\n",
    "meyer_ohe.drop(columns = ['w1q179_ei_r_0', 'w1q180_ei_r_0']).shape\n",
    "meyer_ohe.drop(columns = ['w1q179_ei_r_0', 'w1q180_ei_r_0'], inplace = True)\n",
    "meyer_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c4b3b2-a421-40a0-9c3d-3e0a37f16b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the new columns more semantic names\n",
    "relig_rename = {'w1q179_ei_r_1': 'w1q179_ei_r_relig_christ', 'w1q179_ei_r_5': 'w1q179_ei_r_relig_other', \n",
    "  'w1q180_ei_r_1': 'w1q180_ei_r_relig_christ', 'w1q180_ei_r_5': 'w1q180_ei_r_relig_other'}\n",
    "\n",
    "meyer_ohe.rename(columns = relig_rename, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d34aea17-0aff-4010-8605-0c7ab0795575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 227)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put it back under its own name\n",
    "meyer = meyer_ohe.copy(deep = True)\n",
    "del meyer_ohe\n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cb57d5f-ee8c-43a2-a93c-7fb492892dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 181 is about how often participants attend religious services.  I reverse coded and \n",
    "# 0-based it, so that 0 = \"Never\" and 5 = \"More than once a week\"\n",
    "meyer[['w1q181_ei_r']] = 6-(meyer[['w1q181_ei']])\n",
    "\n",
    "meyer['w1q181_ei'].value_counts(dropna = False).sort_index()\n",
    "meyer['w1q181_ei_r'].value_counts(dropna = False).sort_index()\n",
    "\n",
    "meyer.drop(columns = ['w1q181_ei']).shape\n",
    "meyer.drop(columns = ['w1q181_ei'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ccee22-9749-4261-9707-8a4cd2bc0f15",
   "metadata": {},
   "source": [
    "#### Creating Composite Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346cfeb-f430-48aa-8255-830bf73e5d81",
   "metadata": {},
   "source": [
    "Once each of those columns was recoded to work seamlessly in the model, I began creating composite variables.  These are similar to the scale scores that Meyer and his team included in the dataset, in that they mathematically combine multiple columns into one.  However, these combinations are of my own design, and were not laid out in the codebook.  When choosing which columns to condense into one, I relied on cues from the structure of the questions, as well as my own experience and domain knowledge.\n",
    "\n",
    "Because there were quite a few composite columns I wanted to create, I used a dictionary to organize them, rather than writing out each combination individually.  This is the dictionary that was referenced in the `recode()` function above.  Dynamically updating it while recoding the columns allowed me to iteratively improve upon it, but for the sake of readability, I will simply display the most up-to-date version here.\n",
    "\n",
    "Each entry in the dictionary has the same structure.  The keys are the names I want to assign to the new columns that will be created from a combination of existing columns.  The values are lists.  The first entry in each of those lists is the method by which I wanted to combine the existing columns, and the rest of the entries are the names of those columns.  That is why, when working iteratively, it was so important to update this dictionary every time I recoded, renamed, or dropped a column: the column names in the most up-to-date version of the dictionary had to exactly match the column names in the most up-to-date version of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b014b3b-31fa-417c-9549-3bb8cdd2211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_dict = {\n",
    "  'health_insurance': [\n",
    "    'binarize', 'w1q64_2_ei', 'w1q64_3_ei', 'w1q64_4_ei', 'w1q64_5_ei', 'w1q64_6_ei', 'w1q64_7_ei', \n",
    "    'w1q64_8_ei', 'w1q64_9_ei', 'w1q64_10_ei', 'w1q64_11_ei', 'w1q64_12_ei', 'w1q64_13_ei', 'w1q64_t_num'], \n",
    "  'serious_health_cond': [\n",
    "    'binarize', 'w1q74_5_ei', 'w1q74_6_ei', 'w1q74_10_ei', 'w1q74_11_ei', \n",
    "    'w1q74_14_ei', 'w1q74_17_ei', 'w1q74_18_ei', 'w1q74_20_ei'], \n",
    "  'disabled': [\n",
    "    'binarize', 'w1q75_ei_r', 'w1q76_ei_r'], \n",
    "  'outness': [\n",
    "    'mean', 'w1q123a_ei_r', 'w1q123b_ei_r', 'w1q123c_ei_r', 'w1q123d_ei_r', 'w1q124_ei_r'], \n",
    "  'abusive_treatment': [\n",
    "    'sum', 'w1q135a_ei_r', 'w1q135b_ei_r', 'w1q135c_ei_r', 'w1q135d_ei_r', 'w1q135e_ei_r', 'w1q135f_ei_r'], \n",
    "  'work_neg_outcomes': [\n",
    "    'sum', 'w1q137_ei_r', 'w1q138_ei_r'], \n",
    "  'abus_treat_non_queer': [\n",
    "    'sum', 'w1q136_1_ei', 'w1q136_5_ei', 'w1q136_6_ei', 'w1q136_8_ei', 'w1q136_9_ei', 'w1q136_10_ei'], \n",
    "  'stress_past_year_gen': [\n",
    "    'sum', 'w1q142a_ei_r', 'w1q142h_ei_r', 'w1q142i_ei_r'], \n",
    "  'stress_past_year_work': [\n",
    "    'sum', 'w1q142b_ei_r', 'w1q142c_ei_r', 'w1q142e_ei_r'], \n",
    "  'stress_past_year_interpersonal': [\n",
    "    'sum', 'w1q142d_ei_r', 'w1q142f_ei_r', 'w1q142g_ei_r'], \n",
    "  'stress_past_year_crime': [\n",
    "    'sum', 'w1q142j_ei_r', 'w1q142k_ei_r'], \n",
    "  'work_disc_non_queer': [\n",
    "    'sum', 'w1q139_1_ei', 'w1q139_5_ei', 'w1q139_6_ei', 'w1q139_8_ei', 'w1q139_9_ei', 'w1q139_10_ei'], \n",
    "  'housing_disc_non_queer': [\n",
    "    'sum', 'w1q141_1_ei', 'w1q141_5_ei', 'w1q141_6_ei', 'w1q141_8_ei', 'w1q141_9_ei', 'w1q141_10_ei'], \n",
    "  'stress_past_year_non_queer': [\n",
    "    'sum', 'w1q143_1_ei', 'w1q143_5_ei', 'w1q143_6_ei', 'w1q143_8_ei', 'w1q143_9_ei', 'w1q143_10_ei'], \n",
    "  'daily_discr_non_queer': [\n",
    "    'sum', 'w1q145_1_ei', 'w1q145_5_ei', 'w1q145_6_ei'], \n",
    "  'childhd_bullying_non_queer': [\n",
    "    'sum', 'w1q163_1_ei', 'w1q163_5_ei', 'w1q163_6_ei', 'w1q163_8_ei', 'w1q163_9_ei', 'w1q163_10_ei'], \n",
    "  'abus_treat_sex_gender': [\n",
    "    'sum', 'w1q136_2_ei', 'w1q136_3_ei', 'w1q136_4_ei'], \n",
    "  'work_disc_sex_gender': [\n",
    "    'sum', 'w1q139_2_ei', 'w1q139_3_ei', 'w1q139_4_ei'], \n",
    "  'housing_disc_sex_gender': [\n",
    "    'sum', 'w1q141_2_ei', 'w1q141_3_ei', 'w1q141_4_ei'], \n",
    "  'stress_past_year_sex_gender': [\n",
    "    'sum', 'w1q143_2_ei', 'w1q143_3_ei', 'w1q143_4_ei'], \n",
    "  'daily_discr_sex_gender': [\n",
    "    'sum', 'w1q145_2_ei', 'w1q145_3_ei', 'w1q145_4_ei', 'w1q145_8_ei', 'w1q145_9_ei', 'w1q145_10_ei'], \n",
    "  'childhd_bullying_sex_gender': [\n",
    "    'sum', 'w1q163_2_ei', 'w1q163_3_ei', 'w1q163_4_ei'], \n",
    "  'chronic_strain': [\n",
    "    'sum', 'w1q146a_ei', 'w1q146b_ei', 'w1q146c_ei', 'w1q146d_ei', 'w1q146e_ei', 'w1q146f_ei', 'w1q146g_ei', \n",
    "    'w1q146h_ei', 'w1q146i_ei', 'w1q146j_ei', 'w1q146k_ei', 'w1q146l_ei'], \n",
    "  'bad_neighbhd': [\n",
    "    'sum', 'w1q19a_ei_r', 'w1q19b_ei_r', 'w1q19c_ei_r', 'w1q19d_ei_r'], \n",
    "  'suicidality': ['sum', 'w1q101_ei_r', 'w1q105_ei_r', 'w1q109_ei_r', 'w1q114_ei']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f0c005d-1ddf-495a-95d9-e03f2c75379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 227)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape before combining\n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94ef94-2cca-45d8-bfdb-afa1174b5d10",
   "metadata": {},
   "source": [
    "I used the following for loop to go through each entry in the dictionary and create a new column, with the appropriate name, consisting of the indicated existing columns, combined in the indicated way.  I also included two \"counters\" in the loop to help me keep track of its progress and make sure the resulting dataframe had the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e8dfbc1-0c82-4d98-8cf2-3dc3c1483f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature engineering: 227 columns\n",
      "Feature engineering should add 25 columns, based on 121 columns\n"
     ]
    }
   ],
   "source": [
    "# Keep some records\n",
    "starting_cols = meyer.shape[1]\n",
    "component_cols = sum([len(v[1:]) for v in feat_eng_dict.values()])\n",
    "new_cols = len([k for k in feat_eng_dict.keys()])\n",
    "print(f'Before feature engineering: {starting_cols} columns')\n",
    "print(f'Feature engineering should add {new_cols} columns, based on {component_cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70805a9b-ac18-4681-abe0-695d952f501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Added: 25\n",
      "New Dimensions: (1494, 252)\n",
      "That's correct? True\n",
      "Everyone accounted for? True\n"
     ]
    }
   ],
   "source": [
    "# Create a counter for every (composite) column added\n",
    "cols_added = 0\n",
    "\n",
    "# Create a counter for every (existing) column condensed into a composite column\n",
    "cols_done = []\n",
    "\n",
    "# For each item in the dictionary\n",
    "for k, v in feat_eng_dict.items():\n",
    "  meyer[k] = meyer[v[1]]       # Copy the first component column into a new column with the indicated name. \n",
    "  cols_done.append(v[1])       # Add the first component column to the \"done\" list.\n",
    "  cols_added += 1              # Count the newly added column\n",
    "  for i in v[2:]:              # For every subsequent component column on the list in the dictionary entry\n",
    "    meyer[k] += meyer[i]       # Add its values to those already in the new column (calc a sum)\n",
    "    cols_done.append(i)        # Add it to the \"done\" list - if the method is \"sum\", it's done!\n",
    "  if v[0]=='mean':             # If the method (first entry in the list) is \"mean\"...\n",
    "    meyer[k] = meyer[k]/len(v[1:])     # Divide the new column (sum) by the number of composite columns\n",
    "  elif v[0]=='binarize':               # If the method is \"binarize\"...\n",
    "    meyer[k] = np.where(meyer[k]>1, 1, meyer[k])  # Change any values >1 to 1. Leave current 0s and 1s alone.\n",
    "\n",
    "# Print out the progress numbers at the end\n",
    "print(f'Columns Added: {cols_added}')\n",
    "print(f'New Dimensions: {meyer.shape}')\n",
    "print(f\"That's correct? {(starting_cols + cols_added) == meyer.shape[1]}\")\n",
    "print(f\"Everyone accounted for? {component_cols == len(set(cols_done))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3007f4c6-8c06-4678-ad1c-e33ec0192713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Examples for verification\n",
    "\n",
    "# Binarization calculated by hand\n",
    "meyer['check_disabled'] = (meyer['w1q75_ei_r'] + meyer['w1q76_ei_r'])\n",
    "meyer.loc[(meyer['check_disabled']==2), 'check_disabled'] = 1 \n",
    "# Make sure it matches the automatically generated column; should be two 0s\n",
    "print(sum((meyer['check_disabled']-meyer['disabled'])!=0))\n",
    "print(sum(meyer['check_disabled']!=meyer['disabled']))\n",
    "\n",
    "# Sum calculated by hand\n",
    "meyer['check_suicidality'] = (meyer['w1q101_ei_r'] + meyer['w1q105_ei_r'] + meyer[\n",
    "                              'w1q109_ei_r'] + meyer['w1q114_ei'])\n",
    "# Make sure it matches the automatically generated column; should be two 0s\n",
    "print(sum((meyer['check_suicidality']-meyer['suicidality'])!=0))\n",
    "print(sum(meyer['check_suicidality']!=meyer['suicidality']))\n",
    "\n",
    "# Mean calculated by hand\n",
    "meyer['check_outness'] = (meyer['w1q123a_ei_r'] + meyer['w1q123b_ei_r'] + meyer[\n",
    "  'w1q123c_ei_r'] + meyer['w1q123d_ei_r'] + meyer['w1q124_ei_r'])/len([\n",
    "  'mean', 'w1q123a_ei_r', 'w1q123b_ei_r', 'w1q123c_ei_r', 'w1q123d_ei_r', 'w1q124_ei_r'][1:])\n",
    "# Make sure it matches the automatically generated column; should be two 0s\n",
    "print(sum((meyer['check_outness']-meyer['outness'])!=0))\n",
    "print(sum(meyer['check_outness']!=meyer['outness']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "885bbe88-8e5e-42ea-a6cc-1f73713141a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're ready to drop? True\n"
     ]
    }
   ],
   "source": [
    "# Update the drop list\n",
    "cols_done.append('check_outness')\n",
    "cols_done.append('check_suicidality')\n",
    "cols_done.append('check_disabled')\n",
    "\n",
    "# Calculate how many columns should be left post-drop\n",
    "# started with + new composites + verifications - components - verifications\n",
    "goal = starting_cols + new_cols + 3 - component_cols - 3\n",
    "print(f\"We're ready to drop? {goal==(meyer.drop(columns = cols_done).shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b409ea2e-30ec-48a8-8d33-31a5db85c34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 131)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming that's True\n",
    "meyer.drop(columns = cols_done, inplace = True)\n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "841878db-2012-49a1-ba2a-45f41ec731b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone accounted for? True\n"
     ]
    }
   ],
   "source": [
    "# Reorder the columns\n",
    "ordered_cols = sorted(list(meyer.columns))\n",
    "ordered_cols.remove('studyid')\n",
    "ordered_cols.remove('w1kessler6_i')\n",
    "ordered_cols = ['studyid', 'w1kessler6_i'] + ordered_cols\n",
    "print(f\"Everyone accounted for? {len(ordered_cols)==meyer.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23bc964e-4149-4e25-8bc5-c09f4a6a59ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 131)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meyer = meyer[ordered_cols]\n",
    "meyer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2eafc1-1aaa-4e1e-acd2-b01a04bfc04e",
   "metadata": {},
   "source": [
    "## Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a99455-75cf-4b0b-8fad-2ca36fb3c22a",
   "metadata": {},
   "source": [
    "In this notebook, I finished preparing the data for modeling through feature engineering.  \n",
    "\n",
    "In the following notebook, I will conduct exploratory data analysis to guide my choices in modeling.\n",
    "\n",
    "Any readers who are following along or attempting to reproduce my work should use the cell below to save a copy of the dataframe as it exists now.  A cell is provided at the top of the next notebook in which to import that copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8b124fd-b1d4-4a51-ba3b-42729c354db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the dataframe to use in the next notebook\n",
    "meyer.to_csv('../02_data/df_after_data_preparation_part_2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
